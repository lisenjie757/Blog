{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3c9a18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c1a4b",
   "metadata": {},
   "source": [
    "# 获取训练设备\n",
    "## 查看有无可用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0c29fcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9df1f",
   "metadata": {},
   "source": [
    "# 定义神经网络类\n",
    "## super(NeuralNetwork,self) ：查找NeuralNetwork的父类，对self实施父类的方法\n",
    "## nn.Flatten(x,[start=1,end=-1]) ：对输入张量进行指定维数降维，此处将(1,28,28)降成(1,28*28)\n",
    "## nn.Sequential() ：序列容器，将神经网络模块按顺序添加到容器中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3ce1302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "29ccdca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##将模型移入GPU并打印其网络结构\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e9061e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1336,  0.0304,  0.0931,  0.0339, -0.0094, -0.0008,  0.0166, -0.0240,\n",
      "          0.0925,  0.0196]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.1098, 0.0991, 0.1055, 0.0994, 0.0952, 0.0960, 0.0977, 0.0938, 0.1054,\n",
      "         0.0980]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "##输入数据到模型模块进行推理，不要直接调用model.forward()!!!\n",
    "X = torch.rand(1,28,28,device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(dim=1)\n",
    "print(logits)\n",
    "print(pred_probab)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07625f95",
   "metadata": {},
   "source": [
    "# 模型层解构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4491e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07293b",
   "metadata": {},
   "source": [
    "## nn.Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f7edb86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3479c",
   "metadata": {},
   "source": [
    "## nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "98c90777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2000,  0.2776, -0.7355, -0.3797, -0.1512,  0.0185, -0.5153,  0.1008,\n",
      "         -0.0465, -0.0639,  0.3081, -0.1949, -0.3344, -0.2686, -0.4252,  0.3563,\n",
      "         -0.4522, -0.4960,  0.1055,  0.2331],\n",
      "        [ 0.0975,  0.2940, -0.9692, -0.3690,  0.0631, -0.3411, -0.0673,  0.3240,\n",
      "         -0.1576, -0.1297,  0.3874,  0.1448, -0.0382, -0.0201, -0.3787,  0.0979,\n",
      "         -0.1431, -0.3668,  0.0498,  0.0185],\n",
      "        [ 0.1308,  0.4705, -1.0834, -0.4550, -0.5799, -0.1748, -0.0261,  0.1923,\n",
      "         -0.1883, -0.1687,  0.2970,  0.0997, -0.3435, -0.0668, -0.1730,  0.3838,\n",
      "         -0.5578, -0.2858, -0.3256,  0.2613]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28,out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3ed75",
   "metadata": {},
   "source": [
    "## nn.ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0b9810ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.2000,  0.2776, -0.7355, -0.3797, -0.1512,  0.0185, -0.5153,  0.1008,\n",
      "         -0.0465, -0.0639,  0.3081, -0.1949, -0.3344, -0.2686, -0.4252,  0.3563,\n",
      "         -0.4522, -0.4960,  0.1055,  0.2331],\n",
      "        [ 0.0975,  0.2940, -0.9692, -0.3690,  0.0631, -0.3411, -0.0673,  0.3240,\n",
      "         -0.1576, -0.1297,  0.3874,  0.1448, -0.0382, -0.0201, -0.3787,  0.0979,\n",
      "         -0.1431, -0.3668,  0.0498,  0.0185],\n",
      "        [ 0.1308,  0.4705, -1.0834, -0.4550, -0.5799, -0.1748, -0.0261,  0.1923,\n",
      "         -0.1883, -0.1687,  0.2970,  0.0997, -0.3435, -0.0668, -0.1730,  0.3838,\n",
      "         -0.5578, -0.2858, -0.3256,  0.2613]], grad_fn=<AddmmBackward0>)\n",
      "After ReLU: tensor([[0.2000, 0.2776, 0.0000, 0.0000, 0.0000, 0.0185, 0.0000, 0.1008, 0.0000,\n",
      "         0.0000, 0.3081, 0.0000, 0.0000, 0.0000, 0.0000, 0.3563, 0.0000, 0.0000,\n",
      "         0.1055, 0.2331],\n",
      "        [0.0975, 0.2940, 0.0000, 0.0000, 0.0631, 0.0000, 0.0000, 0.3240, 0.0000,\n",
      "         0.0000, 0.3874, 0.1448, 0.0000, 0.0000, 0.0000, 0.0979, 0.0000, 0.0000,\n",
      "         0.0498, 0.0185],\n",
      "        [0.1308, 0.4705, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1923, 0.0000,\n",
      "         0.0000, 0.2970, 0.0997, 0.0000, 0.0000, 0.0000, 0.3838, 0.0000, 0.0000,\n",
      "         0.0000, 0.2613]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before ReLU: \"+str(hidden1))\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(\"After ReLU: \"+str(hidden1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa354e9",
   "metadata": {},
   "source": [
    "## nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "97ac0515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1867,  0.2772, -0.2026,  0.0006,  0.0781, -0.0579, -0.0299,  0.2266,\n",
      "         -0.2537,  0.1294],\n",
      "        [-0.1681,  0.3171, -0.2369,  0.0297,  0.0926, -0.0527, -0.0191,  0.2763,\n",
      "         -0.3408,  0.1500],\n",
      "        [-0.3777,  0.2138, -0.0585,  0.2183,  0.0368, -0.0401,  0.0495, -0.0046,\n",
      "         -0.2697,  0.3572]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb1fd75",
   "metadata": {},
   "source": [
    "## nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "faf57392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0819, 0.1302, 0.0806, 0.0988, 0.1067, 0.0932, 0.0958, 0.1238, 0.0766,\n",
      "         0.1124],\n",
      "        [0.0824, 0.1339, 0.0769, 0.1004, 0.1070, 0.0925, 0.0957, 0.1285, 0.0693,\n",
      "         0.1133],\n",
      "        [0.0662, 0.1197, 0.0911, 0.1202, 0.1003, 0.0928, 0.1015, 0.0962, 0.0738,\n",
      "         0.1381]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a94ccc",
   "metadata": {},
   "source": [
    "# 模型参数\n",
    "## nn.Moudle会自动跟踪保存模型参数，使用parameters()或named_parameters()获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "37178bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "linear_relu_stack.0.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0136,  0.0086,  0.0201,  ..., -0.0083,  0.0114,  0.0195],\n",
      "        [-0.0292,  0.0223,  0.0234,  ..., -0.0216,  0.0027,  0.0272],\n",
      "        [ 0.0288, -0.0090, -0.0113,  ..., -0.0138,  0.0296,  0.0332],\n",
      "        ...,\n",
      "        [-0.0310,  0.0033,  0.0168,  ...,  0.0356, -0.0144, -0.0318],\n",
      "        [ 0.0150, -0.0069,  0.0163,  ..., -0.0115,  0.0056,  0.0016],\n",
      "        [ 0.0151, -0.0308,  0.0306,  ..., -0.0280, -0.0270, -0.0092]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "linear_relu_stack.0.bias\n",
      "Parameter containing:\n",
      "tensor([-5.1606e-03,  2.0612e-02, -1.1231e-02, -1.7049e-02,  3.4463e-03,\n",
      "         3.5099e-02,  3.3571e-02, -1.5449e-02, -8.1109e-03, -1.7736e-03,\n",
      "        -8.9108e-03, -2.8069e-02,  1.7994e-03, -3.3940e-02,  2.5640e-02,\n",
      "         6.0045e-03, -5.7129e-03,  2.2343e-03, -1.1225e-02,  2.1234e-02,\n",
      "         3.6746e-04, -1.8147e-02,  2.3782e-02, -1.1540e-02, -3.5045e-02,\n",
      "         2.1746e-02, -2.0084e-02,  3.2629e-02,  1.3625e-02,  2.1715e-02,\n",
      "         2.8550e-02,  1.6895e-02,  3.3975e-02, -3.2828e-02,  3.5409e-02,\n",
      "        -1.5760e-02,  1.4441e-04, -1.6164e-02, -9.7296e-03, -3.5436e-02,\n",
      "        -2.1213e-02,  4.2769e-03,  3.4182e-02,  4.4371e-03, -2.3288e-04,\n",
      "         2.9626e-02, -2.1258e-02, -4.7697e-03, -1.7760e-03,  1.0834e-02,\n",
      "        -1.3201e-02, -3.0732e-02, -1.1342e-02,  1.9304e-02,  2.6137e-02,\n",
      "        -6.1194e-03, -1.9214e-02, -2.1956e-02,  1.1286e-02, -3.2967e-02,\n",
      "         2.7857e-02, -1.0782e-02, -1.6390e-02,  1.5589e-02,  7.4068e-03,\n",
      "        -2.9409e-02, -1.3732e-02, -2.7536e-02,  2.7898e-02,  8.4447e-03,\n",
      "         7.0243e-03,  1.2997e-03, -1.1262e-03, -2.1875e-02,  3.0647e-02,\n",
      "         9.5686e-03, -3.1944e-03,  1.0320e-02,  1.9593e-02,  2.9254e-02,\n",
      "        -3.1466e-02,  2.5792e-02,  1.8026e-02,  2.4278e-02,  2.4986e-02,\n",
      "        -3.1689e-02, -1.2860e-02, -2.7822e-02,  2.0790e-02, -3.7081e-03,\n",
      "        -1.8418e-02,  3.2246e-02, -4.3153e-03, -1.2898e-02,  2.8017e-02,\n",
      "         1.0044e-03,  5.4045e-03, -1.3674e-02, -2.8319e-03,  3.2419e-02,\n",
      "        -6.5478e-04, -1.8280e-02, -1.7696e-02, -2.6038e-02,  1.9834e-02,\n",
      "        -1.4796e-02, -5.1452e-04,  1.9523e-02, -2.3560e-02, -2.8977e-02,\n",
      "        -7.4943e-03,  2.0839e-02,  2.0844e-02, -2.6756e-02,  1.2265e-02,\n",
      "         3.8898e-03, -2.8994e-02,  1.8619e-02, -2.7831e-02, -3.1734e-02,\n",
      "         2.3403e-02,  7.3106e-03, -3.5652e-02, -1.5664e-02,  3.0849e-02,\n",
      "        -3.5193e-04,  3.3552e-02, -1.4415e-02,  1.1451e-02,  2.3236e-02,\n",
      "         1.9241e-02,  3.3148e-02,  2.3631e-02, -6.0821e-03,  3.3707e-02,\n",
      "        -5.7217e-03,  1.3281e-02,  3.8301e-03, -1.0509e-02,  2.8188e-02,\n",
      "        -3.5664e-03,  1.7544e-02,  2.8964e-02, -1.9621e-02, -2.9235e-02,\n",
      "         1.5089e-02,  1.4729e-02,  2.7463e-02, -3.5207e-03, -3.0173e-02,\n",
      "         3.2242e-02, -5.2157e-03,  5.4013e-03,  2.4549e-02, -2.3945e-02,\n",
      "         1.6815e-03, -3.3146e-03, -8.1716e-03, -3.3739e-03, -1.6082e-02,\n",
      "         3.4245e-02, -7.0131e-03,  2.8578e-02, -2.0761e-02, -3.1638e-02,\n",
      "        -1.3748e-03,  2.0165e-02,  4.1823e-03,  1.6668e-02,  3.0019e-02,\n",
      "         2.0227e-02, -1.8993e-02,  1.0902e-02, -4.2378e-03,  3.4136e-02,\n",
      "         1.8672e-02, -2.8175e-03, -1.6237e-02,  1.7950e-02, -3.1576e-02,\n",
      "         9.5354e-03,  2.2048e-02, -1.9920e-02, -3.1496e-02,  2.1963e-02,\n",
      "         2.9992e-02,  6.0739e-04, -3.2911e-02,  2.4279e-02, -5.8500e-03,\n",
      "         2.4465e-02, -1.0242e-02,  5.9302e-03,  9.1672e-03,  1.0684e-02,\n",
      "        -2.6612e-03, -5.9599e-03, -1.3328e-02,  2.6054e-02,  1.2235e-02,\n",
      "         2.3132e-02, -1.3633e-02,  2.2585e-02,  4.6598e-03, -8.4742e-03,\n",
      "         2.1985e-02,  2.5938e-02,  1.0077e-03,  3.0372e-02,  2.5991e-02,\n",
      "         2.6608e-02,  3.3820e-02, -3.1075e-02, -3.0528e-02, -2.0487e-02,\n",
      "         2.0621e-02, -2.3335e-03,  2.2124e-02,  2.2410e-02,  4.8040e-03,\n",
      "         1.7646e-02,  1.0325e-02, -2.5818e-02,  3.1500e-02, -1.7250e-02,\n",
      "         8.0122e-03,  1.2274e-02, -1.5816e-02, -1.7269e-02,  3.0728e-02,\n",
      "        -1.3563e-02, -1.4045e-02,  1.4630e-03, -2.6434e-02,  2.9908e-02,\n",
      "        -1.8668e-02, -2.5550e-02, -1.5470e-02,  7.0334e-03,  1.8951e-02,\n",
      "        -9.6366e-04, -2.4024e-02,  1.8632e-02,  2.3023e-02,  2.3204e-02,\n",
      "         9.7846e-04, -2.5365e-02,  3.5537e-03,  1.0104e-02,  2.8966e-02,\n",
      "        -3.5197e-02, -4.3867e-03,  2.6349e-02,  1.3507e-02,  1.0463e-02,\n",
      "         3.1146e-02,  2.4796e-02,  1.8059e-02, -1.1060e-03, -1.2952e-02,\n",
      "        -3.1859e-02,  3.2675e-02, -3.3223e-03, -1.2439e-02, -8.8194e-05,\n",
      "         1.7242e-02,  3.1419e-02, -8.2023e-03,  2.6831e-02,  1.9278e-02,\n",
      "        -2.8360e-02,  7.2907e-03,  1.7108e-02,  2.2032e-02, -2.4227e-02,\n",
      "         2.8565e-03, -2.1770e-02, -3.4752e-02, -2.6796e-02,  1.7457e-02,\n",
      "         2.5389e-02,  7.9730e-03,  2.4993e-02, -2.2456e-02, -9.9800e-03,\n",
      "         2.2580e-03, -3.2734e-02, -8.1340e-04,  2.0545e-03, -4.8773e-03,\n",
      "         3.0941e-02,  1.5887e-02, -1.7336e-02, -2.9642e-02, -3.0186e-02,\n",
      "         9.8663e-03, -2.5764e-03,  1.9445e-02,  1.5654e-02, -8.7489e-03,\n",
      "         1.3306e-02, -1.3611e-02, -1.8772e-02,  1.2233e-02,  3.4104e-02,\n",
      "         2.3813e-02, -1.9228e-02, -2.1712e-02,  5.2036e-03, -2.8004e-03,\n",
      "        -2.5906e-02,  2.0789e-02, -3.0010e-02,  1.3501e-02, -1.6464e-02,\n",
      "         2.8784e-02, -2.7205e-02,  1.1969e-02,  1.4445e-03, -2.9546e-02,\n",
      "         3.5517e-02,  5.9539e-04, -1.2472e-02,  2.6553e-03, -1.7128e-02,\n",
      "        -2.4535e-02, -3.2689e-02, -3.5665e-02, -1.3023e-02,  3.3206e-02,\n",
      "         3.4594e-02,  8.4520e-03,  2.6072e-02,  8.9510e-04, -2.5970e-02,\n",
      "        -2.9301e-02, -1.8002e-02, -3.4717e-02, -8.2355e-03, -5.4797e-03,\n",
      "        -1.5118e-02,  1.5557e-03, -3.5087e-02,  2.0762e-02,  1.8647e-02,\n",
      "         1.1106e-02,  2.8725e-02,  7.9392e-03,  5.0812e-03,  1.6559e-02,\n",
      "        -3.1519e-02, -1.6505e-02, -2.2789e-02,  7.2254e-03,  3.4573e-02,\n",
      "         1.9752e-02, -3.2249e-02,  1.5226e-02, -2.9710e-02, -2.4608e-02,\n",
      "        -9.4805e-04,  1.1230e-02,  2.2178e-02,  9.7601e-03,  3.2764e-02,\n",
      "        -4.0426e-04, -2.5190e-02, -2.9861e-02,  2.2719e-02,  2.3552e-02,\n",
      "         1.6961e-02, -5.9636e-03,  3.2465e-02,  5.0336e-03,  5.9946e-03,\n",
      "         2.5378e-02,  3.5033e-02, -2.7470e-02,  6.3942e-03, -2.5128e-02,\n",
      "        -6.5888e-03, -2.9907e-02,  1.0673e-02,  3.0030e-02, -3.0912e-02,\n",
      "         1.7200e-02, -1.2042e-02, -1.1732e-02,  6.4861e-03,  5.1558e-03,\n",
      "         1.1822e-02,  2.1728e-02,  3.5691e-02,  1.6082e-02,  1.9822e-02,\n",
      "        -2.0611e-02, -2.3708e-02,  1.4298e-02, -6.2127e-03, -1.7880e-02,\n",
      "        -2.4143e-02, -3.2492e-02, -1.2931e-02, -6.6829e-03, -8.2952e-03,\n",
      "        -1.7246e-02, -1.6636e-03, -2.8036e-02,  2.1272e-02, -2.6356e-02,\n",
      "        -1.4119e-02, -2.5657e-02, -1.4893e-02, -1.3103e-02, -2.6541e-02,\n",
      "        -1.5279e-03, -2.3361e-02, -2.0009e-03, -1.2318e-02, -2.1292e-02,\n",
      "        -1.2733e-02,  2.5673e-02,  2.9572e-02, -1.3506e-02,  8.3697e-03,\n",
      "         1.6885e-03, -1.6011e-02, -1.7560e-02,  8.1474e-03,  7.0837e-03,\n",
      "         2.7230e-03, -2.0178e-02, -7.8241e-03, -2.9716e-02, -9.2842e-03,\n",
      "         3.1345e-02, -4.5289e-03,  1.4172e-03, -3.4544e-02, -3.2755e-03,\n",
      "        -2.7692e-02, -7.4317e-03,  1.4203e-02, -1.4241e-02,  2.4159e-02,\n",
      "         1.4631e-02,  3.3819e-02, -3.1921e-02,  3.8562e-03, -7.7082e-03,\n",
      "         1.0003e-02, -3.4838e-02, -3.9271e-03, -3.4812e-02, -1.1586e-02,\n",
      "         1.0871e-02,  6.0560e-03,  1.3137e-02, -1.5795e-02,  3.4854e-02,\n",
      "        -8.9591e-03, -2.4855e-02,  6.1799e-03,  2.1730e-02,  1.6507e-02,\n",
      "        -3.1771e-02, -1.8706e-02,  1.5503e-02, -3.1768e-02, -4.5303e-03,\n",
      "        -2.8163e-02, -5.5675e-03,  1.0424e-02, -2.2341e-02, -1.1326e-02,\n",
      "         1.0487e-02, -3.9405e-03,  1.6778e-02, -8.4509e-03, -2.3145e-02,\n",
      "         2.8766e-02,  2.2990e-02, -1.9354e-02, -6.9872e-03,  2.9807e-02,\n",
      "        -1.1622e-02,  8.1157e-03,  1.3330e-02,  2.8554e-02,  3.0175e-02,\n",
      "         3.3456e-02,  1.9803e-02, -7.1042e-03,  1.1578e-02,  2.3995e-03,\n",
      "        -3.2711e-02,  1.0818e-02, -1.5456e-02, -3.1598e-02,  7.6412e-03,\n",
      "        -1.8472e-02, -1.2758e-02,  3.2178e-02,  7.2946e-03, -2.5691e-02,\n",
      "         2.1150e-02,  1.7293e-03, -2.0312e-02, -1.7759e-02, -7.0092e-03,\n",
      "        -1.3002e-02,  2.9710e-02], device='cuda:0', requires_grad=True)\n",
      "linear_relu_stack.2.weight\n",
      "Parameter containing:\n",
      "tensor([[-3.7217e-02, -2.0737e-02,  1.9022e-03,  ...,  3.3462e-02,\n",
      "         -8.7858e-03,  1.3117e-02],\n",
      "        [ 4.0489e-02,  4.3072e-02,  4.0770e-02,  ...,  3.5925e-05,\n",
      "          1.0010e-02,  4.2654e-02],\n",
      "        [-8.4671e-03, -4.3789e-02,  2.9047e-02,  ..., -3.6208e-02,\n",
      "          3.1483e-02,  7.9432e-04],\n",
      "        ...,\n",
      "        [-2.6367e-02,  1.6873e-02,  7.7430e-03,  ...,  2.9434e-02,\n",
      "          7.4783e-04,  2.5782e-02],\n",
      "        [ 4.3251e-02,  2.0690e-02,  3.2437e-02,  ..., -2.5270e-02,\n",
      "         -3.0075e-02, -8.7717e-03],\n",
      "        [ 2.7938e-03,  3.8070e-03,  1.9711e-02,  ...,  2.2464e-04,\n",
      "          2.6573e-02,  3.2530e-02]], device='cuda:0', requires_grad=True)\n",
      "linear_relu_stack.2.bias\n",
      "Parameter containing:\n",
      "tensor([-2.8879e-02, -4.0790e-02, -1.7560e-02, -1.7277e-02,  3.1277e-02,\n",
      "         4.2423e-02, -1.9292e-02, -3.7681e-02,  2.4926e-02, -1.5194e-02,\n",
      "         7.5214e-03,  3.4695e-02, -1.6874e-02, -1.8199e-02, -3.5478e-02,\n",
      "        -3.3974e-02,  3.9417e-02,  6.0938e-03,  3.1307e-02, -4.0930e-03,\n",
      "         3.2790e-02,  1.9275e-03,  1.5314e-02,  3.9816e-03,  2.0025e-02,\n",
      "         1.6798e-02, -2.6687e-02, -4.0427e-02, -2.4974e-02, -2.8063e-03,\n",
      "        -2.6210e-02,  8.1388e-03,  2.3970e-02,  4.3762e-02, -2.1815e-02,\n",
      "        -1.8700e-02, -6.9846e-03,  3.6442e-02, -4.3042e-03, -2.0793e-02,\n",
      "        -3.6658e-02,  2.9520e-02,  1.7185e-02, -3.0250e-02, -1.1118e-02,\n",
      "         2.6876e-02, -1.6550e-02, -2.3667e-02, -3.3500e-02,  3.1414e-02,\n",
      "        -2.8245e-03, -1.8946e-02, -2.2896e-02, -4.0740e-02, -4.3062e-02,\n",
      "        -8.3932e-03, -6.6450e-03, -2.4604e-02,  4.1624e-02, -6.0970e-03,\n",
      "        -9.5104e-03,  2.2447e-02,  9.2212e-03, -1.6326e-02,  2.3376e-02,\n",
      "        -2.7349e-02, -3.6926e-02, -1.7206e-03, -3.1018e-02, -2.1145e-02,\n",
      "         2.9608e-02, -9.4401e-04,  1.8101e-02, -3.9255e-02, -1.8282e-02,\n",
      "        -4.2474e-02,  3.5762e-02,  3.1352e-02,  3.7860e-02, -3.3815e-02,\n",
      "         2.6450e-02,  3.9751e-02, -6.3841e-03, -8.4244e-04, -2.4288e-02,\n",
      "         3.5587e-02, -6.2421e-03,  6.9119e-04,  4.4116e-02,  2.9624e-02,\n",
      "         2.1433e-02, -2.4374e-02, -3.3047e-02, -5.8489e-03, -2.0594e-02,\n",
      "        -7.9040e-03, -3.4795e-02,  3.8744e-02, -2.2609e-02, -5.2830e-03,\n",
      "        -4.3110e-02, -2.6917e-02, -9.1407e-03, -3.1612e-02, -3.2341e-02,\n",
      "         2.5189e-02, -1.7678e-02,  2.5607e-03,  4.0912e-02,  5.1462e-03,\n",
      "         3.3278e-02,  2.9345e-02, -3.8419e-02, -3.2282e-02, -3.9200e-02,\n",
      "        -2.7297e-02,  5.5303e-03,  2.1866e-03,  1.5344e-02, -2.5664e-02,\n",
      "         1.3601e-02, -3.1045e-02, -3.8145e-02,  4.0546e-03,  3.0604e-03,\n",
      "        -3.4256e-02,  9.7291e-03,  3.1286e-02, -2.5726e-02, -4.0296e-02,\n",
      "         3.6176e-02,  3.6461e-02,  1.5171e-02, -1.4428e-02, -2.3705e-04,\n",
      "        -3.5363e-02, -2.0346e-02,  6.4162e-03,  2.0648e-02,  2.8251e-02,\n",
      "        -1.5031e-02, -3.7930e-02,  1.2289e-02, -3.3684e-02,  2.1242e-02,\n",
      "        -2.6322e-02, -1.0672e-02,  2.5464e-02, -2.6189e-02, -1.9116e-02,\n",
      "         4.6687e-03,  3.9419e-03,  3.5071e-02,  1.4702e-02, -2.7390e-02,\n",
      "        -9.5540e-03,  4.4038e-02, -2.3390e-02, -1.4547e-02, -2.4232e-02,\n",
      "         3.5529e-02, -3.3859e-02, -2.3730e-03,  7.8350e-03,  2.0407e-02,\n",
      "        -4.6865e-03, -3.7756e-02, -1.7126e-02, -1.0178e-02, -4.0241e-02,\n",
      "         1.8395e-02, -4.0655e-02, -4.2901e-02, -1.5838e-03, -1.6173e-02,\n",
      "         1.0510e-02, -3.3666e-02, -8.5745e-03,  6.6910e-03,  7.9843e-03,\n",
      "         4.3621e-02, -2.3249e-02, -5.6424e-04,  2.8301e-02, -3.4561e-03,\n",
      "        -3.5317e-02, -2.4576e-02,  3.1253e-02,  1.4842e-02, -3.5388e-02,\n",
      "         8.9653e-03, -4.0462e-02, -4.0492e-02, -8.3053e-03, -3.7653e-02,\n",
      "         3.8751e-02, -3.5792e-02,  1.0619e-02,  2.2039e-02, -1.2253e-02,\n",
      "        -2.6181e-02,  2.3636e-02,  4.1643e-02,  9.1427e-05,  2.3518e-02,\n",
      "        -4.1380e-02, -1.7850e-02, -1.3361e-02,  1.5080e-02, -3.8206e-03,\n",
      "         1.6206e-02, -1.0265e-03,  4.2143e-02,  4.1945e-03,  2.5996e-03,\n",
      "         8.3036e-03,  4.1686e-03, -1.9095e-02,  1.9549e-02,  3.8721e-02,\n",
      "        -3.6292e-02, -3.5439e-02,  9.9329e-03, -2.9017e-02,  4.0259e-02,\n",
      "        -3.4121e-02,  2.6152e-02, -8.2643e-04, -1.0869e-02,  5.9055e-03,\n",
      "         5.6466e-03,  1.9252e-02,  1.7394e-02, -2.4967e-02, -3.4452e-02,\n",
      "        -7.4987e-03, -3.6018e-02, -4.0217e-02,  3.3263e-03,  3.5818e-02,\n",
      "         3.5957e-02,  2.5215e-02,  3.1184e-02,  6.3741e-03,  2.0544e-02,\n",
      "         2.8632e-02,  6.1382e-04,  1.3476e-02, -2.0315e-02, -4.3457e-02,\n",
      "         2.2462e-03,  2.1354e-02, -3.5054e-02, -1.2040e-02,  3.3339e-03,\n",
      "         3.9085e-02,  2.7260e-02, -2.5459e-02,  3.0218e-02,  1.7270e-02,\n",
      "         1.7842e-02,  4.2278e-03,  5.3168e-03, -3.8562e-02, -1.3196e-02,\n",
      "        -3.5431e-02, -3.7078e-02, -2.9253e-02, -2.9492e-02,  2.9799e-02,\n",
      "        -3.9769e-03, -2.9708e-02,  4.2533e-03,  2.2166e-02,  5.4366e-03,\n",
      "        -4.7845e-04, -2.4854e-02,  3.8729e-02,  9.5110e-03, -4.0801e-02,\n",
      "        -1.6276e-03,  2.2634e-02, -3.2692e-02, -4.2030e-02,  1.0588e-02,\n",
      "        -3.3226e-03, -3.3348e-02, -3.3693e-02,  2.1222e-02, -2.0541e-02,\n",
      "        -1.3075e-02,  2.1053e-02,  2.1986e-02,  2.9323e-02, -1.2867e-02,\n",
      "         1.2532e-02, -3.1361e-02,  3.5215e-02, -2.9243e-02,  2.5239e-02,\n",
      "         2.6741e-02, -3.2871e-02, -1.5977e-02, -1.2369e-03, -3.9797e-02,\n",
      "         2.8128e-02,  2.0667e-02,  2.1343e-02, -3.0325e-03, -8.6652e-03,\n",
      "        -1.5860e-02, -4.1720e-02,  4.1807e-02,  3.9244e-02,  1.3619e-02,\n",
      "        -2.0437e-02, -1.8406e-02,  3.8780e-02,  2.2557e-02, -2.8120e-02,\n",
      "        -1.7985e-03,  4.2581e-02,  1.3097e-02, -2.4756e-02, -3.5956e-02,\n",
      "        -1.7348e-02, -1.3580e-02, -2.1912e-02,  4.1831e-02,  7.1435e-03,\n",
      "        -3.0878e-02,  3.3290e-02,  1.8854e-03,  1.5456e-02, -9.5383e-03,\n",
      "        -3.2220e-02, -7.9768e-05,  3.2062e-02, -6.3458e-03,  1.9938e-03,\n",
      "        -3.9255e-02,  3.1354e-02, -1.0253e-02,  1.0961e-02,  1.0079e-02,\n",
      "         6.0595e-03, -2.4892e-02, -2.4586e-02,  2.3146e-02, -9.4844e-04,\n",
      "         3.4647e-02,  4.0532e-02,  1.4124e-02,  2.8176e-02, -2.1314e-02,\n",
      "        -3.4449e-02, -4.3691e-02, -3.1372e-02, -2.2649e-02, -4.1601e-02,\n",
      "        -2.7056e-02, -2.4502e-02,  4.0753e-02,  2.8846e-02, -3.3910e-02,\n",
      "         3.7248e-02, -2.5389e-02, -2.8439e-02,  1.9999e-02, -3.9432e-02,\n",
      "        -1.1373e-02,  1.3466e-02, -7.7994e-03, -3.4690e-02,  1.2184e-02,\n",
      "         1.3259e-02, -6.1824e-03,  2.3435e-02,  3.5865e-02,  3.5183e-02,\n",
      "        -3.4809e-02, -4.5956e-03,  4.3479e-02, -3.4576e-02, -1.4085e-02,\n",
      "         1.3737e-02, -1.7415e-03, -1.7698e-02, -2.3612e-02, -3.6517e-02,\n",
      "        -1.4923e-02,  1.1429e-02,  3.0523e-02, -1.8723e-02, -3.1247e-03,\n",
      "        -2.5684e-02,  1.9431e-02, -1.7904e-02, -8.5675e-03,  3.0294e-02,\n",
      "        -3.3449e-02,  3.6738e-03, -3.9486e-02, -4.4069e-02, -1.2376e-02,\n",
      "         2.3428e-02,  3.9068e-02, -3.1687e-02, -2.8405e-02, -3.0762e-03,\n",
      "         3.0058e-02,  5.4706e-03,  2.0169e-02,  1.3671e-02,  2.5351e-02,\n",
      "        -3.4149e-02, -3.2129e-02, -3.7714e-02,  3.9049e-02, -2.6183e-02,\n",
      "         8.4614e-03, -9.7251e-03,  1.2936e-03, -1.4387e-02, -2.1004e-02,\n",
      "        -4.0098e-02,  3.3505e-02, -3.2713e-02,  2.2512e-02,  3.1922e-02,\n",
      "         4.1703e-02, -2.9619e-02, -3.0421e-02, -3.9651e-02,  3.1800e-02,\n",
      "         2.3801e-02, -1.8019e-02,  1.1768e-02,  5.5299e-03,  4.3952e-02,\n",
      "        -2.2965e-02,  2.5729e-02, -1.3744e-02, -3.5197e-02, -3.2838e-02,\n",
      "        -1.0003e-02,  1.1235e-03,  3.0280e-02, -2.9854e-02,  1.3382e-02,\n",
      "        -2.3134e-02, -3.1902e-02, -7.3146e-03, -2.5321e-02, -1.4019e-02,\n",
      "        -4.3083e-02,  1.0267e-03, -2.7474e-02, -7.8510e-03, -5.2072e-03,\n",
      "         4.1047e-02, -2.2661e-02, -2.2581e-02, -2.6487e-02,  2.0368e-03,\n",
      "         3.5335e-02, -2.1769e-02, -3.9525e-02,  3.1205e-02, -2.5016e-02,\n",
      "         1.8587e-02,  3.8280e-02, -3.3157e-02,  2.2020e-02, -4.0133e-02,\n",
      "        -2.8128e-02,  6.4883e-03,  1.2212e-02, -4.0281e-02,  1.5328e-02,\n",
      "         3.7102e-02, -3.4552e-02, -3.4747e-03, -6.1605e-03, -4.8928e-03,\n",
      "        -2.3889e-02,  2.7167e-02, -4.8968e-03,  3.2358e-02,  2.5169e-02,\n",
      "         1.8029e-02, -3.5395e-02,  1.4546e-02,  1.7065e-02,  1.3264e-03,\n",
      "         3.2569e-02,  1.4790e-03,  1.5448e-02, -2.1153e-02,  4.0791e-02,\n",
      "         2.6092e-02,  1.9963e-02, -4.2267e-02,  1.3537e-02,  6.1473e-03,\n",
      "         3.8375e-03,  5.0765e-04,  7.1873e-03, -2.5733e-02, -1.1529e-02,\n",
      "         2.8021e-02,  2.8755e-02], device='cuda:0', requires_grad=True)\n",
      "linear_relu_stack.4.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0211,  0.0246,  0.0426,  ..., -0.0025,  0.0361,  0.0355],\n",
      "        [-0.0310,  0.0281,  0.0079,  ...,  0.0169,  0.0365,  0.0276],\n",
      "        [-0.0341,  0.0356, -0.0156,  ...,  0.0299,  0.0097,  0.0347],\n",
      "        ...,\n",
      "        [ 0.0232, -0.0134, -0.0149,  ...,  0.0430,  0.0316,  0.0272],\n",
      "        [ 0.0418,  0.0030, -0.0010,  ...,  0.0099,  0.0163, -0.0412],\n",
      "        [-0.0393,  0.0350,  0.0052,  ..., -0.0044,  0.0215, -0.0203]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "linear_relu_stack.4.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0391,  0.0005, -0.0199,  0.0236, -0.0292,  0.0019, -0.0296, -0.0285,\n",
      "        -0.0181, -0.0135], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "for name,param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt12",
   "language": "python",
   "name": "pt12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
