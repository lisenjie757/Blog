{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.8245, 0.8069],\n",
      "        [0.2119, 0.9145]])\n",
      "tensor([[0.3151, 0.8133, 0.7510],\n",
      "        [0.8190, 0.9030, 0.1693]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "##直接数据创建\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "\n",
    "##通过numpy转换\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)\n",
    "\n",
    "##保持特定属性创建\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(x_ones)\n",
    "x_rand = torch.rand_like(x_data,dtype=torch.float)\n",
    "print(x_rand)\n",
    "\n",
    "##以特定的维度构造特定属性的张量\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "print(rand_tensor)\n",
    "ones_tensor = torch.ones(shape)\n",
    "print(ones_tensor)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9527, 0.5502, 0.1051, 0.5587],\n",
      "        [0.7882, 0.5084, 0.8422, 0.6339],\n",
      "        [0.1735, 0.7458, 0.3827, 0.7142]])\n",
      "torch.Size([3, 4])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "True\n",
      "tensor([[0.9527, 0.5502, 0.1051, 0.5587],\n",
      "        [0.7882, 0.5084, 0.8422, 0.6339],\n",
      "        [0.1735, 0.7458, 0.3827, 0.7142]], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor(12.) <class 'torch.Tensor'>\n",
      "12.0 <class 'float'>\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "##张量在GPU运算\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "tensor = tensor.to('cuda')\n",
    "print(tensor)\n",
    "\n",
    "##标准索引和切片运算\n",
    "tensor = torch.ones(4,4)\n",
    "print(tensor[0])\n",
    "print(tensor[:,0])\n",
    "print(tensor[...,-1])\n",
    "tensor[...,1] = 0\n",
    "print(tensor)\n",
    "\n",
    "##张量连接运算\n",
    "t1 = torch.cat([tensor,tensor,tensor],dim=1)\n",
    "print(t1)\n",
    "\n",
    "##矩阵乘法（下面三种写法是一样的）\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor,tensor.T,out=y3)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n",
    "\n",
    "##矩阵对应元素点乘（下面三种写法是一样的）\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor,tensor,out=z3)\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)\n",
    "\n",
    "##单元素张量（可转换为Python元素）\n",
    "agg = tensor.sum()\n",
    "print(agg,type(agg))\n",
    "agg_item = agg.item()\n",
    "print(agg_item,type(agg_item))\n",
    "\n",
    "##原地张量运算（计算微分时会丢失历史信息，不建议使用）\n",
    "print(tensor)\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 与Numpy互相转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## tensor to numpy\n",
    "t = torch.ones(5)\n",
    "print(t)\n",
    "n = t.numpy()\n",
    "print(n)\n",
    "\n",
    "## numpy to tensor\n",
    "n = np.ones(5)\n",
    "print(n)\n",
    "t = torch.from_numpy(n)\n",
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt12",
   "language": "python",
   "name": "pt12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
